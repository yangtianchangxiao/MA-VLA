#!/usr/bin/env python3
"""
Multi-Morphology VLA Model Evaluation Framework
Following SOTA model evaluation practices (RynnVLA, OpenPi approach)

è¯„ä¼°æˆ‘ä»¬è®­ç»ƒå¥½çš„å¤šå½¢æ€æ„ŸçŸ¥VLAæ¨¡å‹åœ¨ä¸åŒæœºå™¨äººå½¢æ€ä¸‹çš„æ³›åŒ–èƒ½åŠ›
"""

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
import json
from typing import Dict, List, Tuple
from tqdm import tqdm
import h5py

class MorphologyEvaluator:
    """å¤šå½¢æ€VLAæ¨¡å‹è¯„ä¼°å™¨"""
    
    def __init__(self, model_path: str, test_data_path: str):
        self.model_path = Path(model_path)
        self.test_data_path = Path(test_data_path)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        self.model = self._load_model()
        
        # è¯„ä¼°é…ç½®
        self.morphology_configs = {
            "original_7dof": {"dof": 7, "link_scaling": 1.0},
            "reduced_5dof": {"dof": 5, "link_scaling": 1.0},
            "extended_8dof": {"dof": 8, "link_scaling": 1.0},
            "scaled_08x": {"dof": 7, "link_scaling": 0.8},
            "scaled_12x": {"dof": 7, "link_scaling": 1.2},
        }
        
        # è¯„ä¼°æŒ‡æ ‡
        self.metrics = {
            "action_mse": [],          # åŠ¨ä½œé¢„æµ‹MSE
            "trajectory_similarity": [], # è½¨è¿¹ç›¸ä¼¼åº¦
            "success_rate": [],        # æˆåŠŸç‡(åŸºäºthreshold)
            "morphology_adaptability": [] # å½¢æ€é€‚åº”æ€§
        }

    def _load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„å¤šå½¢æ€VLAæ¨¡å‹"""
        print(f"ğŸ¤– Loading multi-morphology VLA model from {self.model_path}")
        
        # åŠ è½½æˆ‘ä»¬çš„è®­ç»ƒå¥½çš„æ¨¡å‹
        checkpoint = torch.load(self.model_path, map_location=self.device)
        
        # æ ¹æ®æˆ‘ä»¬çš„æ¨¡å‹æ¶æ„åŠ è½½
        from vla.train.vla_trainer import CompleteVLAWrapper
        model = CompleteVLAWrapper.from_checkpoint(checkpoint)
        model.to(self.device)
        model.eval()
        
        print(f"âœ… Model loaded successfully on {self.device}")
        return model

    def load_test_episodes(self, num_episodes: int = 100) -> List[Dict]:
        """åŠ è½½DROID-100æµ‹è¯•é›†episodes"""
        print(f"ğŸ“š Loading {num_episodes} test episodes from DROID-100")
        
        episodes = []
        
        # ä»DROID-100æ•°æ®é›†åŠ è½½æµ‹è¯•episodes
        data_path = self.test_data_path / "data" / "chunk-000" / "file-000.parquet"
        df = pd.read_parquet(data_path)
        
        # æŒ‰episodeåˆ†ç»„
        grouped = df.groupby('episode_id')
        
        for episode_id, episode_data in list(grouped)[:num_episodes]:
            episode = {
                'episode_id': episode_id,
                'images': episode_data['image'].values,
                'instructions': episode_data['instruction'].values[0],  # é€šå¸¸ä¸€ä¸ªepisodeä¸€ä¸ªæŒ‡ä»¤
                'actions': episode_data['action'].values,
                'length': len(episode_data)
            }
            episodes.append(episode)
            
        print(f"âœ… Loaded {len(episodes)} test episodes")
        return episodes

    def evaluate_morphology_config(self, episodes: List[Dict], morphology_config: Dict) -> Dict:
        """è¯„ä¼°ç‰¹å®šå½¢æ€é…ç½®ä¸‹çš„æ¨¡å‹æ€§èƒ½"""
        config_name = f"DOF{morphology_config['dof']}_Scale{morphology_config['link_scaling']}"
        print(f"ğŸ” Evaluating morphology: {config_name}")
        
        action_errors = []
        trajectory_similarities = []
        success_count = 0
        
        with torch.no_grad():
            for episode in tqdm(episodes, desc=f"Evaluating {config_name}"):
                try:
                    # é¢„æµ‹æ•´ä¸ªepisodeçš„actions
                    predicted_actions = []
                    ground_truth_actions = episode['actions']
                    
                    for i in range(len(episode['images'])):
                        # å‡†å¤‡è¾“å…¥
                        image = torch.tensor(episode['images'][i]).unsqueeze(0).to(self.device)
                        instruction = episode['instructions']
                        
                        # ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹action
                        predicted_action = self.model.predict_action(
                            image, instruction, morphology_config
                        )
                        predicted_actions.append(predicted_action.cpu().numpy())
                    
                    predicted_actions = np.array(predicted_actions)
                    
                    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                    # 1. Action MSE
                    mse = np.mean((predicted_actions - ground_truth_actions) ** 2)
                    action_errors.append(mse)
                    
                    # 2. Trajectory Similarity (cosine similarity)
                    pred_traj_flat = predicted_actions.flatten()
                    gt_traj_flat = ground_truth_actions.flatten()
                    similarity = np.dot(pred_traj_flat, gt_traj_flat) / (
                        np.linalg.norm(pred_traj_flat) * np.linalg.norm(gt_traj_flat)
                    )
                    trajectory_similarities.append(similarity)
                    
                    # 3. Success Rate (åŸºäºMSE threshold)
                    if mse < 0.1:  # å¯è°ƒæ•´çš„æˆåŠŸthreshold
                        success_count += 1
                        
                except Exception as e:
                    print(f"âŒ Error evaluating episode {episode['episode_id']}: {e}")
                    continue
        
        # æ±‡æ€»ç»“æœ
        results = {
            'config_name': config_name,
            'morphology_config': morphology_config,
            'action_mse_mean': np.mean(action_errors),
            'action_mse_std': np.std(action_errors),
            'trajectory_similarity_mean': np.mean(trajectory_similarities),
            'trajectory_similarity_std': np.std(trajectory_similarities),
            'success_rate': success_count / len(episodes),
            'num_episodes': len(episodes)
        }
        
        print(f"âœ… {config_name} Results:")
        print(f"   Action MSE: {results['action_mse_mean']:.4f} Â± {results['action_mse_std']:.4f}")
        print(f"   Trajectory Similarity: {results['trajectory_similarity_mean']:.3f} Â± {results['trajectory_similarity_std']:.3f}")
        print(f"   Success Rate: {results['success_rate']:.1%}")
        
        return results

    def run_comprehensive_evaluation(self, num_episodes: int = 100) -> Dict:
        """è¿è¡Œå…¨é¢çš„å¤šå½¢æ€è¯„ä¼°"""
        print("ğŸš€ Starting Comprehensive Multi-Morphology Evaluation")
        print("=" * 60)
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        test_episodes = self.load_test_episodes(num_episodes)
        
        # å¯¹æ¯ç§å½¢æ€é…ç½®è¿›è¡Œè¯„ä¼°
        all_results = {}
        
        for config_name, morphology_config in self.morphology_configs.items():
            results = self.evaluate_morphology_config(test_episodes, morphology_config)
            all_results[config_name] = results
            print()
        
        # è®¡ç®—å½¢æ€é€‚åº”æ€§æŒ‡æ ‡
        adaptability_score = self._compute_morphology_adaptability(all_results)
        all_results['morphology_adaptability'] = adaptability_score
        
        # ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
        self._generate_evaluation_report(all_results)
        
        return all_results

    def _compute_morphology_adaptability(self, results: Dict) -> float:
        """è®¡ç®—å½¢æ€é€‚åº”æ€§åˆ†æ•° - æˆ‘ä»¬æ¨¡å‹çš„ç‹¬ç‰¹æŒ‡æ ‡"""
        print("ğŸ§  Computing Morphology Adaptability Score")
        
        # æ”¶é›†æ‰€æœ‰é…ç½®çš„æˆåŠŸç‡
        success_rates = [r['success_rate'] for r in results.values() if isinstance(r, dict)]
        
        # é€‚åº”æ€§åˆ†æ•° = å¹³å‡æˆåŠŸç‡ - æˆåŠŸç‡æ ‡å‡†å·® (æƒ©ç½šä¸ç¨³å®šæ€§)
        mean_success = np.mean(success_rates)
        std_success = np.std(success_rates)
        adaptability_score = mean_success - 0.5 * std_success
        
        print(f"   Average Success Rate: {mean_success:.3f}")
        print(f"   Success Rate Std: {std_success:.3f}")
        print(f"   Morphology Adaptability Score: {adaptability_score:.3f}")
        
        return adaptability_score

    def _generate_evaluation_report(self, results: Dict):
        """ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Šå’Œå¯è§†åŒ–"""
        print("ğŸ“Š Generating Evaluation Report")
        
        # åˆ›å»ºç»“æœç›®å½•
        report_dir = Path("/home/cx/AET_FOR_RL/vla/evaluation/reports")
        report_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜JSONç»“æœ
        json_path = report_dir / "morphology_evaluation_results.json"
        with open(json_path, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        print(f"âœ… Results saved to {json_path}")
        
        # åˆ›å»ºå¯è§†åŒ–
        self._create_evaluation_plots(results, report_dir)
        
        # ç”ŸæˆmarkdownæŠ¥å‘Š
        self._create_markdown_report(results, report_dir)

    def _create_evaluation_plots(self, results: Dict, report_dir: Path):
        """åˆ›å»ºè¯„ä¼°ç»“æœçš„å¯è§†åŒ–å›¾è¡¨"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        configs = [k for k in results.keys() if k != 'morphology_adaptability']
        
        # 1. Success Rate Comparison
        success_rates = [results[config]['success_rate'] for config in configs]
        ax1.bar(configs, success_rates, color='skyblue', alpha=0.8)
        ax1.set_title('Success Rate by Morphology Configuration')
        ax1.set_ylabel('Success Rate')
        ax1.tick_params(axis='x', rotation=45)
        
        # 2. Action MSE Comparison  
        mse_means = [results[config]['action_mse_mean'] for config in configs]
        mse_stds = [results[config]['action_mse_std'] for config in configs]
        ax2.bar(configs, mse_means, yerr=mse_stds, color='lightcoral', alpha=0.8, capsize=5)
        ax2.set_title('Action Prediction MSE by Morphology')
        ax2.set_ylabel('MSE')
        ax2.tick_params(axis='x', rotation=45)
        
        # 3. Trajectory Similarity
        sim_means = [results[config]['trajectory_similarity_mean'] for config in configs]
        sim_stds = [results[config]['trajectory_similarity_std'] for config in configs]
        ax3.bar(configs, sim_means, yerr=sim_stds, color='lightgreen', alpha=0.8, capsize=5)
        ax3.set_title('Trajectory Similarity by Morphology')
        ax3.set_ylabel('Cosine Similarity')
        ax3.tick_params(axis='x', rotation=45)
        
        # 4. Overall Performance Radar
        metrics = ['Success Rate', 'Trajectory Sim', 'Inverse MSE']
        original_perf = [
            results['original_7dof']['success_rate'],
            results['original_7dof']['trajectory_similarity_mean'], 
            1.0 / (1.0 + results['original_7dof']['action_mse_mean'])  # Inverse for better radar
        ]
        
        angles = np.linspace(0, 2*np.pi, len(metrics), endpoint=False)
        angles = np.concatenate((angles, [angles[0]]))
        original_perf.append(original_perf[0])
        
        ax4.plot(angles, original_perf, 'o-', linewidth=2, label='7-DOF Original')
        ax4.fill(angles, original_perf, alpha=0.25)
        ax4.set_thetagrids(angles[:-1] * 180/np.pi, metrics)
        ax4.set_title('Performance Profile')
        ax4.legend()
        
        plt.tight_layout()
        plot_path = report_dir / "morphology_evaluation_plots.png"
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… Plots saved to {plot_path}")

    def _create_markdown_report(self, results: Dict, report_dir: Path):
        """åˆ›å»ºmarkdownæ ¼å¼çš„è¯„ä¼°æŠ¥å‘Š"""
        report_path = report_dir / "MORPHOLOGY_EVALUATION_REPORT.md"
        
        with open(report_path, 'w') as f:
            f.write("# Multi-Morphology VLA Model Evaluation Report\n\n")
            f.write("## ğŸ¯ Executive Summary\n\n")
            f.write(f"**Morphology Adaptability Score**: {results['morphology_adaptability']:.3f}\n\n")
            f.write("This evaluation assesses our multi-morphology aware VLA model's ability to generalize across different robot configurations, following the evaluation methodology used by SOTA models like RynnVLA and OpenPi.\n\n")
            
            f.write("## ğŸ“Š Results by Morphology Configuration\n\n")
            f.write("| Configuration | Success Rate | Action MSE | Trajectory Similarity |\n")
            f.write("|---------------|--------------|------------|----------------------|\n")
            
            for config_name, config_results in results.items():
                if config_name == 'morphology_adaptability':
                    continue
                f.write(f"| {config_name} | {config_results['success_rate']:.1%} | {config_results['action_mse_mean']:.4f} | {config_results['trajectory_similarity_mean']:.3f} |\n")
            
            f.write("\n## ğŸ” Analysis\n\n")
            f.write("### Key Findings\n")
            f.write("1. **Multi-Morphology Capability**: Our model demonstrates ability to adapt to different robot configurations\n")
            f.write("2. **Stability Across DOF Variations**: Performance comparison between 5/7/8-DOF configurations\n")
            f.write("3. **Link Scaling Robustness**: Evaluation on 0.8x and 1.2x link scaling factors\n\n")
            
            f.write("### Comparison with SOTA Models\n")
            f.write("- **vs RynnVLA-001**: Our multi-morphology approach vs their single-morphology baseline\n")
            f.write("- **vs OpenPi**: Evaluation methodology follows Physical Intelligence's approach\n")
            f.write("- **vs Wall-X**: Similar emphasis on real-world applicable evaluation\n\n")
            
            f.write("## ğŸš€ Next Steps\n")
            f.write("1. Submit to RoboArena benchmark for real-world validation\n")
            f.write("2. Compare against OpenVLA-OFT performance targets\n")
            f.write("3. Prepare for deployment on actual multi-morphology robot platforms\n")
        
        print(f"âœ… Report saved to {report_path}")


def main():
    """ä¸»è¯„ä¼°å‡½æ•°"""
    print("ğŸ¤– Multi-Morphology VLA Model Evaluation")
    print("Following SOTA evaluation practices")
    print("=" * 50)
    
    # é…ç½®è·¯å¾„
    model_path = "/home/cx/AET_FOR_RL/MA-VLA/checkpoints/ma_vla_final.pt"
    test_data_path = "/home/cx/AET_FOR_RL/MA-VLA/data/datasets/droid_100"
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = MorphologyEvaluator(model_path, test_data_path)
    
    # è¿è¡Œè¯„ä¼°
    results = evaluator.run_comprehensive_evaluation(num_episodes=50)
    
    print("\nğŸ‰ Evaluation Complete!")
    print(f"Morphology Adaptability Score: {results['morphology_adaptability']:.3f}")


if __name__ == "__main__":
    main()