#!/usr/bin/env python3
"""
Teacher-Student Distillation Training
ä½¿ç”¨RynnVLA-001ä½œä¸ºteacherï¼Œé€šè¿‡è¿ç»­IKç”Ÿæˆè®­ç»ƒæ•°æ®
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import json
import os
from pathlib import Path
from tqdm import tqdm
import random
from scipy.spatial.transform import Rotation as R

# Import our models
from vla_model import RealRynnVLALoRAGNN
from vla_trainer import CompleteVLADataset

class ContinuousIKSolver:
    """è¿ç»­IKæ±‚è§£å™¨ï¼Œé¿å…å¤šè§£è·³è·ƒ"""

    def __init__(self, num_joints=7):
        self.num_joints = num_joints
        self.prev_joint_config = None
        self.joint_limits = self._get_joint_limits()

    def _get_joint_limits(self):
        """è·å–å…³èŠ‚é™åˆ¶ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”ä»URDFè·å–ï¼‰"""
        # 7-DOFæœºæ¢°è‡‚çš„å…¸å‹å…³èŠ‚é™åˆ¶
        limits = {
            'lower': np.array([-2.8, -1.7, -2.8, -3.1, -2.8, -0.0, -2.8]),
            'upper': np.array([2.8, 1.7, 2.8, -0.0, 2.8, 3.8, 2.8])
        }
        return limits

    def solve_continuous_ik(self, cartesian_trajectory, base_morphology):
        """
        è¿ç»­IKæ±‚è§£ï¼Œç¡®ä¿è§£çš„è¿ç»­æ€§

        Args:
            cartesian_trajectory: [seq_len, 6] - (x,y,z,rx,ry,rz) trajectory
            base_morphology: dict - æœºå™¨äººå½¢æ€å‚æ•°

        Returns:
            joint_trajectory: [seq_len, num_joints] - è¿ç»­çš„å…³èŠ‚è½¨è¿¹
        """
        seq_len = cartesian_trajectory.shape[0]
        joint_trajectory = np.zeros((seq_len, self.num_joints))

        # å¦‚æœæ˜¯é¦–æ¬¡è°ƒç”¨ï¼Œåˆå§‹åŒ–å…³èŠ‚é…ç½®
        if self.prev_joint_config is None:
            self.prev_joint_config = np.zeros(self.num_joints)

        for t in range(seq_len):
            target_pose = cartesian_trajectory[t]  # [x, y, z, rx, ry, rz]

            # ç®€åŒ–çš„IKæ±‚è§£ï¼ˆå®é™…åº”ä½¿ç”¨æ›´ç²¾ç¡®çš„ç®—æ³•å¦‚KDL/Pinocchioï¼‰
            joint_config = self._solve_ik_single_step(
                target_pose,
                self.prev_joint_config,
                base_morphology
            )

            joint_trajectory[t] = joint_config
            self.prev_joint_config = joint_config

        return joint_trajectory

    def _solve_ik_single_step(self, target_pose, prev_joints, morphology):
        """
        å•æ­¥IKæ±‚è§£ï¼Œä¿è¯ä¸å‰ä¸€æ­¥çš„è¿ç»­æ€§

        Args:
            target_pose: [6] - ç›®æ ‡ä½å§¿
            prev_joints: [num_joints] - å‰ä¸€æ­¥å…³èŠ‚è§’åº¦
            morphology: dict - æœºå™¨äººå½¢æ€

        Returns:
            joint_config: [num_joints] - ä¼˜åŒ–åçš„å…³èŠ‚é…ç½®
        """
        # ç®€åŒ–å®ç°ï¼šåŸºäºå‰ä¸€æ­¥å…³èŠ‚è§’åº¦è¿›è¡Œå¾®è°ƒ
        # å®é™…å®ç°éœ€è¦ä½¿ç”¨æ•°å€¼IKæˆ–è§£æIK

        target_pos = target_pose[:3]
        target_rot = target_pose[3:6]

        # ä½¿ç”¨æ¢¯åº¦ä¸‹é™ä¼˜åŒ–å…³èŠ‚è§’åº¦
        joint_config = prev_joints.copy()

        # ç®€åŒ–çš„è¿­ä»£ä¼˜åŒ–
        for iteration in range(10):  # é™åˆ¶è¿­ä»£æ¬¡æ•°
            # è®¡ç®—å½“å‰æ­£è¿åŠ¨å­¦
            current_pose = self._forward_kinematics(joint_config, morphology)

            # è®¡ç®—è¯¯å·®
            pos_error = target_pos - current_pose[:3]
            rot_error = target_rot - current_pose[3:6]

            # ç®€å•çš„æ¢¯åº¦æ›´æ–°ï¼ˆå®é™…åº”è®¡ç®—é›…å¯æ¯”çŸ©é˜µï¼‰
            pos_gradient = pos_error * 0.1
            rot_gradient = rot_error * 0.05

            # æ›´æ–°å…³èŠ‚è§’åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰
            joint_config[:3] += pos_gradient
            joint_config[3:6] += rot_gradient

            # ç¡®ä¿å…³èŠ‚åœ¨é™åˆ¶èŒƒå›´å†…
            joint_config = np.clip(joint_config,
                                 self.joint_limits['lower'],
                                 self.joint_limits['upper'])

            # æ£€æŸ¥æ”¶æ•›
            if np.linalg.norm(pos_error) < 0.001 and np.linalg.norm(rot_error) < 0.01:
                break

        # ä¼˜å…ˆé€‰æ‹©ä¸å‰ä¸€æ­¥æœ€æ¥è¿‘çš„è§£ï¼ˆé¿å…è·³è·ƒï¼‰
        return self._select_continuous_solution(joint_config, prev_joints)

    def _forward_kinematics(self, joint_config, morphology):
        """ç®€åŒ–çš„æ­£è¿åŠ¨å­¦è®¡ç®—"""
        # å®é™…å®ç°éœ€è¦ä½¿ç”¨DHå‚æ•°æˆ–URDF
        # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„å‡ ä½•è®¡ç®—

        # è·å–å½¢æ€å‚æ•°
        link_lengths = morphology.get('link_lengths', [0.3, 0.3, 0.3, 0.2, 0.2, 0.1, 0.05])

        # ç®€åŒ–çš„FKè®¡ç®—
        x = sum(link_lengths[i] * np.cos(sum(joint_config[:i+1])) for i in range(min(3, len(joint_config))))
        y = sum(link_lengths[i] * np.sin(sum(joint_config[:i+1])) for i in range(min(3, len(joint_config))))
        z = sum(link_lengths[i] * joint_config[i] * 0.1 for i in range(3, min(len(joint_config), 6)))

        # ç®€åŒ–çš„æ–¹å‘è®¡ç®—
        rx = joint_config[3] if len(joint_config) > 3 else 0
        ry = joint_config[4] if len(joint_config) > 4 else 0
        rz = joint_config[5] if len(joint_config) > 5 else 0

        return np.array([x, y, z, rx, ry, rz])

    def _select_continuous_solution(self, candidate_config, prev_config):
        """é€‰æ‹©ä¸å‰ä¸€æ­¥æœ€è¿ç»­çš„è§£"""
        # è®¡ç®—é…ç½®ç©ºé—´è·ç¦»
        config_distance = np.linalg.norm(candidate_config - prev_config)

        # å¦‚æœè·ç¦»è¿‡å¤§ï¼Œå¯èƒ½å‘ç”Ÿäº†è·³è·ƒï¼Œéœ€è¦è°ƒæ•´
        max_joint_change = 0.2  # å•æ­¥æœ€å¤§å…³èŠ‚å˜åŒ–ï¼ˆå¼§åº¦ï¼‰

        adjusted_config = candidate_config.copy()
        for i in range(len(candidate_config)):
            joint_change = candidate_config[i] - prev_config[i]

            if abs(joint_change) > max_joint_change:
                # é™åˆ¶å˜åŒ–å¹…åº¦
                adjusted_config[i] = prev_config[i] + np.sign(joint_change) * max_joint_change

        return adjusted_config

class TeacherStudentDistiller:
    """Teacher-Studentè’¸é¦è®­ç»ƒå™¨"""

    def __init__(self,
                 teacher_model_path="/home/cx/AET_FOR_RL/vla/å‚è€ƒæ¨¡å‹/RynnVLA-001/pretrained_models/RynnVLA-001-7B-Base",
                 student_model_path="/home/cx/AET_FOR_RL/vla/train/vla_model_trained.pth",
                 device="cuda:0"):

        self.device = torch.device(device)
        self.action_chunk_size = 20

        print(f"ğŸ“ Teacher-Student Distillation Initializing...")
        print(f"   Teacher: {teacher_model_path}")
        print(f"   Student: {student_model_path}")
        print(f"   Device: {self.device}")

        # åˆå§‹åŒ–è¿ç»­IKæ±‚è§£å™¨
        self.ik_solver = ContinuousIKSolver()

        # åŠ è½½Teacheræ¨¡å‹ï¼ˆRynnVLA-001ï¼‰
        self.teacher_model = self._load_teacher_model(teacher_model_path)

        # åŠ è½½Studentæ¨¡å‹ï¼ˆæˆ‘ä»¬çš„GNNæ¨¡å‹ï¼‰
        self.student_model = self._load_student_model(student_model_path)

        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            self.student_model.parameters(),
            lr=1e-4,
            weight_decay=0.01
        )

        print("âœ… Teacher-Student models loaded successfully!")

    def _load_teacher_model(self, model_path):
        """åŠ è½½RynnVLA-001ä½œä¸ºteacher"""
        try:
            # è¿™é‡Œåº”è¯¥åŠ è½½é¢„è®­ç»ƒçš„RynnVLA-001
            # æš‚æ—¶ä½¿ç”¨æˆ‘ä»¬çš„æ¶æ„ä½œä¸ºå ä½ç¬¦
            base_model = RealRynnVLALoRAGNN(
                model_path=model_path,
                lora_rank=8,
                gnn_node_dim=256,
                action_chunk_size=self.action_chunk_size
            )

            teacher = base_model.to(self.device)
            teacher.eval()

            print("ğŸ“š Teacher model (RynnVLA-001) loaded")
            return teacher

        except Exception as e:
            print(f"âš ï¸ Failed to load teacher model: {e}")
            print("ğŸ”„ Using simplified teacher for development...")
            return None

    def _load_student_model(self, model_path):
        """åŠ è½½æˆ‘ä»¬è®­ç»ƒçš„studentæ¨¡å‹"""
        try:
            # é‡å»ºstudentæ¶æ„
            base_model = RealRynnVLALoRAGNN(
                model_path="/home/cx/AET_FOR_RL/vla/å‚è€ƒæ¨¡å‹/RynnVLA-001/pretrained_models/RynnVLA-001-7B-Base",
                lora_rank=8,
                gnn_node_dim=256,
                action_chunk_size=self.action_chunk_size
            )

            # ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„wrapper
            from vla_trainer import CompleteVLAWrapper
            student = CompleteVLAWrapper(base_model).to(self.device)

            # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
            if os.path.exists(model_path):
                checkpoint = torch.load(model_path, map_location=self.device)
                student.load_state_dict(checkpoint['model_state_dict'])
                print(f"ğŸ“– Student model loaded from checkpoint")
            else:
                print(f"ğŸ†• Student model initialized randomly (no checkpoint found)")

            return student

        except Exception as e:
            print(f"âŒ Failed to load student model: {e}")
            return None

    def generate_synthetic_data(self, num_samples=1000, morphologies_list=None):
        """ç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ®"""
        print(f"ğŸ”„ Generating {num_samples} synthetic training samples...")

        if morphologies_list is None:
            morphologies_list = [
                {"dof": 5, "link_lengths": [0.3, 0.3, 0.3, 0.2, 0.2]},
                {"dof": 6, "link_lengths": [0.3, 0.3, 0.3, 0.2, 0.2, 0.1]},
                {"dof": 7, "link_lengths": [0.3, 0.3, 0.3, 0.2, 0.2, 0.1, 0.05]}
            ]

        synthetic_data = []

        for i in tqdm(range(num_samples)):
            # éšæœºé€‰æ‹©å½¢æ€
            morphology = random.choice(morphologies_list)

            # ç”Ÿæˆéšæœºè¾“å…¥
            sample = self._generate_random_input(morphology)

            # Teacherç”Ÿæˆç¬›å¡å°”è½¨è¿¹
            cartesian_trajectory = self._teacher_inference(sample)

            # IKè½¬æ¢ä¸ºå…³èŠ‚è½¨è¿¹
            joint_trajectory = self.ik_solver.solve_continuous_ik(
                cartesian_trajectory, morphology
            )

            # æ„å»ºè®­ç»ƒæ ·æœ¬
            training_sample = {
                'images': sample['images'],
                'description_tokens': sample['description_tokens'],
                'morphology_features': sample['morphology_features'],
                'target_joint_trajectory': torch.tensor(joint_trajectory, dtype=torch.float32),
                'morphology': morphology,
                'cartesian_trajectory': cartesian_trajectory
            }

            synthetic_data.append(training_sample)

        print(f"âœ… Generated {len(synthetic_data)} synthetic samples")
        return synthetic_data

    def _generate_random_input(self, morphology):
        """ç”Ÿæˆéšæœºè¾“å…¥æ•°æ®"""
        batch_size = 1

        # éšæœºå›¾åƒ (å®é™…åº”è¯¥æ˜¯çœŸå®çš„ç¯å¢ƒå›¾åƒ)
        images = torch.randn(batch_size, 3, 320, 180, device=self.device)

        # éšæœºæŒ‡ä»¤tokens (å®é™…åº”è¯¥æ˜¯æœ‰æ„ä¹‰çš„æŒ‡ä»¤)
        description_tokens = torch.randn(batch_size, 32, device=self.device)

        # å½¢æ€ç‰¹å¾
        dof = morphology["dof"]
        morphology_features = torch.tensor([
            dof / 7.0,  # å½’ä¸€åŒ–DOF
            1.0, 1.0, 1.0,  # é“¾é•¿ç¼©æ”¾
            0.0, 0.0  # åŸºåº§ä½ç½®
        ], device=self.device).unsqueeze(0)  # [1, 6]

        return {
            'images': images,
            'description_tokens': description_tokens,
            'morphology_features': morphology_features,
            'dof': dof
        }

    def _teacher_inference(self, sample):
        """Teacheræ¨¡å‹æ¨ç†ç”Ÿæˆç¬›å¡å°”è½¨è¿¹"""
        if self.teacher_model is None:
            # å¦‚æœteacheræ¨¡å‹æœªåŠ è½½ï¼Œç”Ÿæˆéšæœºè½¨è¿¹ç”¨äºæµ‹è¯•
            seq_len = self.action_chunk_size
            trajectory = np.random.uniform(-1, 1, (seq_len, 6))  # [seq_len, 6] for (x,y,z,rx,ry,rz)

            # ä½¿è½¨è¿¹æ›´åˆç†ä¸€äº›
            for t in range(1, seq_len):
                trajectory[t] = trajectory[t-1] * 0.9 + trajectory[t] * 0.1  # å¹³æ»‘åŒ–

            return trajectory

        # å®é™…çš„teacheræ¨ç†
        try:
            with torch.no_grad():
                # ä½¿ç”¨teacheræ¨¡å‹ç”ŸæˆåŠ¨ä½œ
                outputs = self.teacher_model(
                    sample['images'],
                    sample['description_tokens'],
                    sample['morphology_features'],
                    num_joints=sample['dof']
                )

                # å‡è®¾teacherè¾“å‡ºç¬›å¡å°”ç©ºé—´åŠ¨ä½œ
                actions = outputs['actions']  # [1, action_dim, seq_len]

                # è½¬æ¢ä¸ºè½¨è¿¹æ ¼å¼ [seq_len, 6]
                if actions.shape[-1] == self.action_chunk_size:
                    cartesian_trajectory = actions[0, :6, :].transpose(0, 1).cpu().numpy()
                else:
                    # å¦‚æœä¸æ˜¯æœŸæœ›æ ¼å¼ï¼Œä½¿ç”¨éšæœºè½¨è¿¹
                    cartesian_trajectory = np.random.uniform(-1, 1, (self.action_chunk_size, 6))

                return cartesian_trajectory

        except Exception as e:
            print(f"âš ï¸ Teacher inference failed: {e}, using random trajectory")
            return np.random.uniform(-1, 1, (self.action_chunk_size, 6))

    def train_student(self, synthetic_data, epochs=10, batch_size=8):
        """è®­ç»ƒstudentæ¨¡å‹"""
        print(f"ğŸ¯ Training student model...")
        print(f"   Data samples: {len(synthetic_data)}")
        print(f"   Epochs: {epochs}")
        print(f"   Batch size: {batch_size}")

        self.student_model.train()

        for epoch in range(epochs):
            epoch_loss = 0.0
            num_batches = 0

            # éšæœºæ‰“ä¹±æ•°æ®
            random.shuffle(synthetic_data)

            # æ‰¹å¤„ç†è®­ç»ƒ
            for i in range(0, len(synthetic_data), batch_size):
                batch = synthetic_data[i:i+batch_size]

                if len(batch) == 0:
                    continue

                # å‡†å¤‡batchæ•°æ®
                batch_images = torch.stack([sample['images'].squeeze(0) for sample in batch])
                batch_descriptions = torch.stack([sample['description_tokens'].squeeze(0) for sample in batch])
                batch_morphology = torch.stack([sample['morphology_features'].squeeze(0) for sample in batch])
                batch_targets = torch.stack([sample['target_joint_trajectory'] for sample in batch])

                # Studentæ¨ç†
                self.optimizer.zero_grad()

                outputs = self.student_model(
                    batch_images,
                    batch_descriptions,
                    batch_morphology
                )

                predicted_trajectories = outputs['actions']  # [batch, num_joints, seq_len]

                # è®¡ç®—æŸå¤± (éœ€è¦åŒ¹é…ç»´åº¦)
                # batch_targets: [batch, seq_len, num_joints]
                # predicted: [batch, num_joints, seq_len]
                target_trajectories = batch_targets.transpose(1, 2)  # [batch, num_joints, seq_len]

                loss = nn.MSELoss()(predicted_trajectories, target_trajectories)

                # åå‘ä¼ æ’­
                loss.backward()
                self.optimizer.step()

                epoch_loss += loss.item()
                num_batches += 1

            avg_loss = epoch_loss / max(num_batches, 1)
            print(f"Epoch {epoch+1}/{epochs}: Loss = {avg_loss:.6f}")

            # ä¿å­˜checkpoint
            if (epoch + 1) % 5 == 0:
                self._save_checkpoint(epoch, avg_loss)

        print("âœ… Student training completed!")

    def _save_checkpoint(self, epoch, loss):
        """ä¿å­˜è®­ç»ƒcheckpoint"""
        checkpoint_path = f"/home/cx/AET_FOR_RL/vla/train/student_distilled_epoch_{epoch+1}.pth"

        torch.save({
            'epoch': epoch + 1,
            'model_state_dict': self.student_model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'loss': loss,
        }, checkpoint_path)

        print(f"ğŸ’¾ Checkpoint saved: {checkpoint_path}")

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    print("ğŸš€ Starting Teacher-Student Distillation Training")
    print("=" * 60)

    # åˆå§‹åŒ–distiller
    distiller = TeacherStudentDistiller()

    if distiller.student_model is None:
        print("âŒ Failed to initialize student model")
        return

    # ç”Ÿæˆåˆæˆæ•°æ®
    synthetic_data = distiller.generate_synthetic_data(num_samples=500)  # å…ˆç”¨å°æ•°æ®é›†æµ‹è¯•

    # è®­ç»ƒstudent
    distiller.train_student(synthetic_data, epochs=20, batch_size=4)

    print("\nğŸ‰ Teacher-Student distillation completed!")
    print("ğŸ”¥ Now you have a student model trained on continuous IK labels!")

if __name__ == "__main__":
    main()