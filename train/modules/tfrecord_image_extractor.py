#!/usr/bin/env python3
"""
TFRecordå›¾åƒæå–å™¨ - ä»å®˜æ–¹DROID TFRecordä¸­æå–å›¾åƒæ•°æ®
æ”¯æŒå¤šæ‘„åƒå¤´è§†è§’å’Œä¸cartesian_positionæ•°æ®å¯¹é½
"""
import os
import json
import numpy as np
import tensorflow as tf
from pathlib import Path
from PIL import Image
import cv2
from tqdm import tqdm
from typing import Dict, List, Tuple


class TFRecordImageExtractor:
    """ä»å®˜æ–¹DROID TFRecordä¸­æå–å›¾åƒæ•°æ®"""

    def __init__(self, tfrecord_dir: str):
        self.tfrecord_dir = tfrecord_dir
        self.tfrecord_files = [f for f in os.listdir(tfrecord_dir)
                              if 'tfrecord' in f and f.startswith('r2d2')]

        print(f"ğŸ¥ TFRecord Image Extractor initialized")
        print(f"   Found {len(self.tfrecord_files)} TFRecord files")

    def extract_images_for_episodes(self, valid_episodes: List[int],
                                  output_dir: str,
                                  cameras: List[str] = None,
                                  max_frames_per_episode: int = 100) -> Dict:
        """ä¸ºæŒ‡å®šepisodesæå–å›¾åƒæ•°æ®"""

        if cameras is None:
            cameras = ['exterior_image_1_left', 'exterior_image_2_left', 'wrist_image_left']

        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        print(f"ğŸ¯ æå–å›¾åƒæ•°æ®:")
        print(f"   ç›®æ ‡episodes: {len(valid_episodes)} ä¸ª")
        print(f"   æ‘„åƒå¤´: {cameras}")
        print(f"   è¾“å‡ºç›®å½•: {output_dir}")

        extracted_data = {
            'metadata': {
                'extractor': 'TFRecordImageExtractor',
                'source': 'Official DROID TFRecord',
                'cameras': cameras,
                'total_episodes': len(valid_episodes),
                'max_frames_per_episode': max_frames_per_episode
            },
            'episodes': {},
            'statistics': {
                'successful_episodes': 0,
                'total_frames_extracted': 0,
                'failed_episodes': []
            }
        }

        episode_idx = 0
        valid_episode_set = set(valid_episodes)

        for tfrecord_file in tqdm(sorted(self.tfrecord_files), desc="Processing TFRecords"):
            file_path = os.path.join(self.tfrecord_dir, tfrecord_file)

            try:
                dataset = tf.data.TFRecordDataset([file_path])

                for raw_record in dataset:
                    if episode_idx not in valid_episode_set:
                        episode_idx += 1
                        continue

                    try:
                        episode_data = self._extract_episode_images(
                            raw_record, episode_idx, cameras,
                            output_path, max_frames_per_episode)

                        if episode_data['frame_count'] > 0:
                            extracted_data['episodes'][episode_idx] = episode_data
                            extracted_data['statistics']['successful_episodes'] += 1
                            extracted_data['statistics']['total_frames_extracted'] += episode_data['frame_count']
                        else:
                            extracted_data['statistics']['failed_episodes'].append(episode_idx)

                    except Exception as e:
                        print(f"     âŒ Episode {episode_idx} extraction failed: {e}")
                        extracted_data['statistics']['failed_episodes'].append(episode_idx)

                    episode_idx += 1

            except Exception as e:
                print(f"   âŒ Failed to process {tfrecord_file}: {e}")
                continue

        # ä¿å­˜æå–ç»“æœå…ƒæ•°æ®
        summary_file = output_path / "extraction_summary.json"
        with open(summary_file, 'w') as f:
            json.dump(extracted_data, f, indent=2, default=self._json_serializer)

        print(f"\nâœ… å›¾åƒæå–å®Œæˆ:")
        print(f"   æˆåŠŸepisodes: {extracted_data['statistics']['successful_episodes']}")
        print(f"   æ€»å¸§æ•°: {extracted_data['statistics']['total_frames_extracted']}")
        print(f"   å¤±è´¥episodes: {len(extracted_data['statistics']['failed_episodes'])}")
        print(f"   æ‘˜è¦æ–‡ä»¶: {summary_file}")

        return extracted_data

    def _extract_episode_images(self, raw_record, episode_idx: int,
                               cameras: List[str], output_path: Path,
                               max_frames: int) -> Dict:
        """ä»å•ä¸ªepisodeæå–å›¾åƒæ•°æ®"""

        # åˆ›å»ºepisodeç›®å½•
        episode_dir = output_path / f"episode_{episode_idx:03d}"
        episode_dir.mkdir(exist_ok=True)

        episode_data = {
            'episode_index': episode_idx,
            'cameras': {},
            'frame_count': 0,
            'episode_dir': str(episode_dir)
        }

        try:
            # è§£æTFRecord
            example = tf.train.Example()
            example.ParseFromString(raw_record.numpy())
            features = example.features.feature

            # ä¸ºæ¯ä¸ªæ‘„åƒå¤´åˆ›å»ºç›®å½•
            for camera in cameras:
                camera_dir = episode_dir / camera
                camera_dir.mkdir(exist_ok=True)
                episode_data['cameras'][camera] = {
                    'directory': str(camera_dir),
                    'frames': []
                }

            # æå–å›¾åƒåºåˆ—
            frame_count = 0

            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å›¾åƒæ•°æ®
            image_field_key = f'steps/observation/{cameras[0]}'
            if image_field_key not in features:
                print(f"     âš ï¸ Episode {episode_idx}: æœªæ‰¾åˆ°å›¾åƒå­—æ®µ {image_field_key}")
                return episode_data

            # è·å–å›¾åƒæ•°æ®
            for camera in cameras:
                image_field = f'steps/observation/{camera}'

                if image_field in features:
                    image_data_list = features[image_field].bytes_list.value

                    for frame_idx, image_bytes in enumerate(image_data_list[:max_frames]):
                        try:
                            # è§£ç JPEGå›¾åƒ
                            image_array = tf.image.decode_jpeg(image_bytes).numpy()

                            # è½¬æ¢ä¸ºPIL Image
                            pil_image = Image.fromarray(image_array)

                            # ä¿å­˜å›¾åƒ
                            frame_filename = f"frame_{frame_idx:04d}.jpg"
                            frame_path = episode_dir / camera / frame_filename
                            pil_image.save(frame_path, 'JPEG', quality=90)

                            episode_data['cameras'][camera]['frames'].append({
                                'frame_index': frame_idx,
                                'filename': frame_filename,
                                'path': str(frame_path),
                                'shape': image_array.shape
                            })

                        except Exception as e:
                            print(f"     âš ï¸ Frame {frame_idx} decode failed: {e}")
                            continue

                    frame_count = max(frame_count, len(episode_data['cameras'][camera]['frames']))

            episode_data['frame_count'] = frame_count

        except Exception as e:
            print(f"     âŒ Episode {episode_idx} parsing failed: {e}")

        return episode_data

    def create_frame_index(self, extraction_summary_path: str) -> Dict:
        """åˆ›å»ºå¸§ç´¢å¼•ï¼Œç”¨äºå¿«é€ŸæŸ¥æ‰¾ç‰¹å®štimestepçš„å›¾åƒ"""

        with open(extraction_summary_path, 'r') as f:
            summary = json.load(f)

        frame_index = {}

        for episode_idx, episode_data in summary['episodes'].items():
            episode_idx = int(episode_idx)

            for frame_idx in range(episode_data['frame_count']):
                timestep_key = f"ep_{episode_idx:03d}_frame_{frame_idx:04d}"

                frame_index[timestep_key] = {
                    'episode_index': episode_idx,
                    'frame_index': frame_idx,
                    'image_paths': {}
                }

                for camera, camera_data in episode_data['cameras'].items():
                    if frame_idx < len(camera_data['frames']):
                        frame_info = camera_data['frames'][frame_idx]
                        frame_index[timestep_key]['image_paths'][camera] = frame_info['path']

        return frame_index

    def _json_serializer(self, obj):
        """JSONåºåˆ—åŒ–è¾…åŠ©å‡½æ•°"""
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.integer):
            return int(obj)
        return obj


def main():
    """æµ‹è¯•TFRecordå›¾åƒæå–å™¨"""
    import argparse

    parser = argparse.ArgumentParser(description='Extract images from DROID TFRecord')
    parser.add_argument('--input', default='/home/cx/AET_FOR_RL/vla/original_data/droid_100/1.0.0',
                       help='TFRecord directory')
    parser.add_argument('--output', default='/home/cx/AET_FOR_RL/vla/extracted_images',
                       help='Output directory for images')
    parser.add_argument('--episodes', default='/home/cx/AET_FOR_RL/vla/valid_original_data/droid_100/task_descriptions.json',
                       help='Valid episodes JSON file')
    parser.add_argument('--max-frames', type=int, default=50,
                       help='Maximum frames per episode')
    args = parser.parse_args()

    # è¯»å–æœ‰æ•ˆepisodes
    with open(args.episodes, 'r') as f:
        task_data = json.load(f)
    valid_episodes = task_data['valid_episode_list']

    print(f"ğŸ¯ æå–å›¾åƒæ•°æ®:")
    print(f"   TFRecordç›®å½•: {args.input}")
    print(f"   è¾“å‡ºç›®å½•: {args.output}")
    print(f"   æœ‰æ•ˆepisodes: {len(valid_episodes)}")
    print(f"   æœ€å¤§å¸§æ•°: {args.max_frames}")

    # åˆ›å»ºæå–å™¨
    extractor = TFRecordImageExtractor(args.input)

    # æå–å›¾åƒ
    result = extractor.extract_images_for_episodes(
        valid_episodes, args.output, max_frames_per_episode=args.max_frames)

    # åˆ›å»ºå¸§ç´¢å¼•
    summary_path = os.path.join(args.output, "extraction_summary.json")
    frame_index = extractor.create_frame_index(summary_path)

    index_file = os.path.join(args.output, "frame_index.json")
    with open(index_file, 'w') as f:
        json.dump(frame_index, f, indent=2)

    print(f"   ğŸ“‹ å¸§ç´¢å¼•: {index_file} ({len(frame_index)} entries)")
    print("ğŸ‰ å›¾åƒæå–å®Œæˆ!")


if __name__ == "__main__":
    main()