#!/usr/bin/env python3
"""
è½¯ä½“è‡‚Graph VLAè®­ç»ƒè„šæœ¬ - åŸºäºå®˜æ–¹OpenPiè®­ç»ƒè„šæœ¬çš„æœ€å°åŒ–ä¿®æ”¹
ç¬¦åˆLinusåŸåˆ™: å¤ç”¨æ‰€æœ‰å®˜æ–¹åŸºç¡€è®¾æ–½ï¼Œåªæ›¿æ¢å¿…è¦ç»„ä»¶

ä½¿ç”¨æ–¹æ³•:
å•GPU: python scripts/train_soft_arm.py
å¤šGPU: torchrun --standalone --nnodes=1 --nproc_per_node=8 scripts/train_soft_arm.py
"""

import dataclasses
import gc
import logging
import os
import platform
import shutil
import sys
import time

import jax
import numpy as np
import safetensors.torch
import torch
import torch.distributed as dist
import torch.nn.parallel
import tqdm
import wandb
import yaml

# æ·»åŠ OpenPiè·¯å¾„
sys.path.append('/home/cx/AET_FOR_RL/vla/å‚è€ƒæ¨¡å‹/openpi/src')

# å¯¼å…¥å®˜æ–¹OpenPiç»„ä»¶
import openpi.models.pi0_config
import openpi.shared.normalize as _normalize
import openpi.training.config as _config

# å¯¼å…¥æˆ‘ä»¬çš„æ‰©å±•ç»„ä»¶
sys.path.append('/home/cx/AET_FOR_RL/vla/openpi_soft_arm_training')
from models.pi0_graph_extension import PI0PytorchWithGraph, create_soft_arm_pi0_config
from data.soft_arm_data_adapter import create_soft_arm_openpi_dataloader


class SoftArmTrainConfig:
    """è½¯ä½“è‡‚è®­ç»ƒé…ç½® - æ‰©å±•å®˜æ–¹é…ç½®"""

    def __init__(self, config_path: str = None):
        # åŠ è½½YAMLé…ç½®
        if config_path is None:
            config_path = "/home/cx/AET_FOR_RL/vla/openpi_soft_arm_training/configs/soft_arm_config.yaml"

        with open(config_path, 'r') as f:
            self.config_dict = yaml.safe_load(f)

        # åŸºç¡€è®­ç»ƒé…ç½®
        self.exp_name = self.config_dict['experiment']['name']
        self.project_name = self.config_dict.get('logging', {}).get('wandb_project', 'soft-arm-graph-vla')

        # æ•°æ®é…ç½®
        data_config = self.config_dict['data']
        self.processed_data_dir = data_config['processed_dir']
        self.batch_size = data_config['batch_size']
        self.num_workers = data_config.get('num_workers', 4)

        # è®­ç»ƒé…ç½®
        train_config = self.config_dict['training']
        self.num_train_steps = train_config['max_steps']
        self.save_interval = train_config['save_interval']
        self.log_interval = train_config['log_interval']

        # æ¨¡å‹é…ç½®
        model_config = self.config_dict['model']
        self.action_dim = model_config['max_dof']  # 10DoF
        self.action_horizon = model_config['action_chunk_size']  # 16
        self.max_token_len = model_config.get('max_token_len', 1024)
        self.enable_graph = model_config.get('graph', {}).get('enabled', True)

        # ä¼˜åŒ–å™¨é…ç½®
        optimizer_config = train_config['optimizer']
        self.peak_lr = float(optimizer_config['lr'])
        self.weight_decay = float(optimizer_config['weight_decay'])
        self.b1, self.b2 = optimizer_config['betas']
        self.clip_gradient_norm = float(train_config['grad_clip_norm'])

        # å­¦ä¹ ç‡è°ƒåº¦
        self.warmup_steps = 1000  # å›ºå®šwarmup
        self.decay_steps = self.num_train_steps
        self.decay_lr = float(train_config['scheduler']['eta_min'])

        # ç³»ç»Ÿé…ç½®
        output_config = self.config_dict['output']
        self.checkpoint_dir_base = output_config['checkpoint_dir']
        self.wandb_enabled = self.config_dict.get('logging', {}).get('use_wandb', False)  # é»˜è®¤å…³é—­wandb

        # DDPé…ç½®
        self.pytorch_training_precision = torch.bfloat16  # æ··åˆç²¾åº¦
        self.seed = 42

        # æ„å»ºå®Œæ•´çš„checkpointè·¯å¾„
        self.checkpoint_dir = os.path.join(self.checkpoint_dir_base, self.exp_name)

        # å…¶ä»–é€‰é¡¹
        self.resume = False
        self.overwrite = False
        self.pytorch_weight_path = model_config.get('pretrained_checkpoint')

        print(f"âœ… è½¯ä½“è‡‚è®­ç»ƒé…ç½®å·²åŠ è½½:")
        print(f"   å®éªŒåç§°: {self.exp_name}")
        print(f"   æ•°æ®ç›®å½•: {self.processed_data_dir}")
        print(f"   æ‰¹é‡å¤§å°: {self.batch_size}")
        print(f"   è®­ç»ƒæ­¥æ•°: {self.num_train_steps}")
        print(f"   åŠ¨ä½œç»´åº¦: {self.action_dim}DoF Ã— {self.action_horizon}æ­¥")
        print(f"   å›¾æ”¯æŒ: {'âœ…' if self.enable_graph else 'âŒ'}")


def init_logging():
    """åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ - å¤ç”¨å®˜æ–¹å®ç°"""
    level_mapping = {"DEBUG": "D", "INFO": "I", "WARNING": "W", "ERROR": "E", "CRITICAL": "C"}

    class CustomFormatter(logging.Formatter):
        def format(self, record):
            record.levelname = level_mapping.get(record.levelname, record.levelname)
            return super().format(record)

    formatter = CustomFormatter(
        fmt="%(asctime)s.%(msecs)03d [%(levelname)s] %(message)-80s (%(process)d:%(filename)s:%(lineno)s)",
        datefmt="%H:%M:%S",
    )
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    if not logger.handlers:
        ch = logging.StreamHandler()
        ch.setFormatter(formatter)
        logger.addHandler(ch)
    else:
        logger.handlers[0].setFormatter(formatter)


def setup_ddp():
    """è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒ - å¤ç”¨å®˜æ–¹å®ç°"""
    world_size = int(os.environ.get("WORLD_SIZE", "1"))
    use_ddp = world_size > 1
    if use_ddp and not torch.distributed.is_initialized():
        backend = "nccl" if torch.cuda.is_available() else "gloo"
        torch.distributed.init_process_group(backend=backend, init_method="env://")

        if os.environ.get("TORCH_DISTRIBUTED_DEBUG") is None:
            os.environ["TORCH_DISTRIBUTED_DEBUG"] = "INFO"

    local_rank = int(os.environ.get("LOCAL_RANK", os.environ.get("RANK", "0")))
    device = torch.device(f"cuda:{local_rank}" if torch.cuda.is_available() else "cpu")
    if torch.cuda.is_available():
        torch.cuda.set_device(device)
    return use_ddp, local_rank, device


def build_soft_arm_datasets(config: SoftArmTrainConfig):
    """æ„å»ºè½¯ä½“è‡‚æ•°æ®é›† - æˆ‘ä»¬çš„è‡ªå®šä¹‰å®ç°"""

    # è®­ç»ƒæ•°æ®åŠ è½½å™¨
    train_loader = create_soft_arm_openpi_dataloader(
        processed_data_dir=config.processed_data_dir,
        split='train',
        batch_size=config.batch_size
    )

    # éªŒè¯æ•°æ®åŠ è½½å™¨
    val_loader = create_soft_arm_openpi_dataloader(
        processed_data_dir=config.processed_data_dir,
        split='val',
        batch_size=config.batch_size
    )

    # è·å–æ•°æ®é…ç½®
    data_config = train_loader.data_config()

    print(f"âœ… è½¯ä½“è‡‚æ•°æ®é›†å·²æ„å»º")
    print(f"   è®­ç»ƒåŠ è½½å™¨: {len(train_loader.dataset)} ä¸ªæ ·æœ¬")
    print(f"   éªŒè¯åŠ è½½å™¨: {len(val_loader.dataset)} ä¸ªæ ·æœ¬")

    return train_loader, data_config


def create_soft_arm_model(config: SoftArmTrainConfig, device):
    """åˆ›å»ºè½¯ä½“è‡‚æ¨¡å‹ - æˆ‘ä»¬çš„æ ¸å¿ƒä¿®æ”¹"""

    # åˆ›å»ºPi0é…ç½®
    pi0_config = create_soft_arm_pi0_config(
        action_dim=config.action_dim,
        action_horizon=config.action_horizon,
        max_token_len=config.max_token_len
    )

    # ä½¿ç”¨æˆ‘ä»¬çš„æ‰©å±•æ¨¡å‹
    model = PI0PytorchWithGraph(pi0_config, enable_graph=config.enable_graph).to(device)

    # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ (å¦‚æœæ”¯æŒ)
    if hasattr(model, "gradient_checkpointing_enable"):
        model.gradient_checkpointing_enable()
        print("âœ… å·²å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹")

    return model


def train_loop(config: SoftArmTrainConfig):
    """ä¸»è®­ç»ƒå¾ªç¯ - å¤ç”¨å®˜æ–¹é€»è¾‘ï¼Œæœ€å°åŒ–ä¿®æ”¹"""

    use_ddp, local_rank, device = setup_ddp()
    is_main = (not use_ddp) or (dist.get_rank() == 0)

    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(config.seed + local_rank)
    np.random.seed(config.seed + local_rank)

    # åˆ›å»ºcheckpointç›®å½•
    os.makedirs(config.checkpoint_dir, exist_ok=True)

    # åˆå§‹åŒ–wandb (ä»…ä¸»è¿›ç¨‹)
    if is_main and config.wandb_enabled:
        wandb.init(
            name=config.exp_name,
            config=config.config_dict,
            project=config.project_name
        )

    # æ„å»ºæ•°æ®é›† - ä½¿ç”¨æˆ‘ä»¬çš„è½¯ä½“è‡‚æ•°æ®
    train_loader, data_config = build_soft_arm_datasets(config)

    # æ„å»ºæ¨¡å‹ - ä½¿ç”¨æˆ‘ä»¬çš„å›¾æ‰©å±•æ¨¡å‹
    model = create_soft_arm_model(config, device)

    # DDPåŒ…è£…
    if use_ddp:
        model = torch.nn.parallel.DistributedDataParallel(
            model,
            device_ids=[device.index] if device.type == "cuda" else None,
            find_unused_parameters=True,
            gradient_as_bucket_view=True,
        )

    # åŠ è½½é¢„è®­ç»ƒæƒé‡ (å¦‚æœæŒ‡å®š)
    if config.pytorch_weight_path and os.path.exists(config.pytorch_weight_path):
        model_path = os.path.join(config.pytorch_weight_path, "model.safetensors")
        if os.path.exists(model_path):
            safetensors.torch.load_model(
                (model.module if isinstance(model, torch.nn.parallel.DistributedDataParallel) else model),
                model_path
            )
            print(f"âœ… å·²åŠ è½½é¢„è®­ç»ƒæƒé‡: {config.pytorch_weight_path}")

    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config.peak_lr,
        betas=(config.b1, config.b2),
        weight_decay=config.weight_decay,
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    def lr_schedule(step: int):
        if step < config.warmup_steps:
            init_lr = config.peak_lr / (config.warmup_steps + 1)
            return init_lr + (config.peak_lr - init_lr) * step / config.warmup_steps
        # cosine decay
        progress = min(1.0, (step - config.warmup_steps) / max(1, config.decay_steps - config.warmup_steps))
        cos = 0.5 * (1 + np.cos(np.pi * progress))
        return config.decay_lr + (config.peak_lr - config.decay_lr) * cos

    # è®­ç»ƒå¾ªç¯
    model.train()
    global_step = 0
    start_time = time.time()
    infos = []

    if is_main:
        print(f"ğŸš€ å¼€å§‹è½¯ä½“è‡‚Graph VLAè®­ç»ƒ")
        print(f"   è®¾å¤‡: {device}")
        print(f"   æ‰¹é‡å¤§å°: {config.batch_size}")
        print(f"   è®­ç»ƒæ­¥æ•°: {config.num_train_steps}")
        print(f"   åˆ†å¸ƒå¼: {use_ddp} (world_size={torch.distributed.get_world_size() if use_ddp else 1})")

    pbar = tqdm.tqdm(total=config.num_train_steps, desc="è®­ç»ƒä¸­", disable=not is_main) if is_main else None

    while global_step < config.num_train_steps:
        for observation, actions in train_loader:
            if global_step >= config.num_train_steps:
                break

            # è½¬ç§»æ•°æ®åˆ°è®¾å¤‡
            # observationå·²ç»æ˜¯OpenPiæœŸæœ›çš„å¯¹è±¡æ ¼å¼
            observation.images = jax.tree.map(
                lambda x: x.to(device) if hasattr(x, 'to') else x,
                observation.images
            )
            actions = actions.to(torch.float32).to(device)

            # æå–å›¾æ•°æ® (å¦‚æœæœ‰)
            obs_dict = observation.to_dict()
            graph_data = obs_dict.get('graph_data', None)
            if graph_data is not None:
                graph_data = jax.tree.map(
                    lambda x: x.to(device) if hasattr(x, 'to') else x,
                    graph_data
                )

            # æ›´æ–°å­¦ä¹ ç‡
            for pg in optimizer.param_groups:
                pg["lr"] = lr_schedule(global_step)

            # å‰å‘ä¼ æ’­ - å…³é”®: ä¼ é€’graph_dataç»™æˆ‘ä»¬çš„æ‰©å±•æ¨¡å‹
            losses = model(observation, actions, graph_data=graph_data)

            if isinstance(losses, (list, tuple)):
                losses = torch.stack(losses)
            elif not isinstance(losses, torch.Tensor):
                losses = torch.tensor(losses, device=device, dtype=torch.float32)

            loss = losses.mean()

            # åå‘ä¼ æ’­
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config.clip_gradient_norm)

            # ä¼˜åŒ–å™¨æ­¥éª¤
            optimizer.step()
            optimizer.zero_grad(set_to_none=True)

            # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
            if is_main:
                infos.append({
                    "loss": loss.item(),
                    "learning_rate": optimizer.param_groups[0]["lr"],
                    "grad_norm": float(grad_norm) if isinstance(grad_norm, torch.Tensor) else grad_norm,
                })

            # æ—¥å¿—è®°å½•
            if is_main and (global_step % config.log_interval == 0):
                elapsed = time.time() - start_time
                avg_loss = sum(info["loss"] for info in infos) / len(infos)
                avg_lr = sum(info["learning_rate"] for info in infos) / len(infos)

                print(f"step={global_step} loss={avg_loss:.4f} lr={avg_lr:.2e} time={elapsed:.1f}s")

                if config.wandb_enabled:
                    wandb.log({
                        "loss": avg_loss,
                        "learning_rate": avg_lr,
                        "step": global_step,
                    }, step=global_step)

                start_time = time.time()
                infos = []

            # ä¿å­˜checkpoint
            if is_main and (global_step % config.save_interval == 0) and global_step > 0:
                ckpt_dir = os.path.join(config.checkpoint_dir, f"{global_step}")
                os.makedirs(ckpt_dir, exist_ok=True)

                # ä¿å­˜æ¨¡å‹
                model_to_save = model.module if isinstance(model, torch.nn.parallel.DistributedDataParallel) else model
                safetensors.torch.save_model(model_to_save, os.path.join(ckpt_dir, "model.safetensors"))

                # ä¿å­˜ä¼˜åŒ–å™¨
                torch.save(optimizer.state_dict(), os.path.join(ckpt_dir, "optimizer.pt"))

                # ä¿å­˜å…ƒæ•°æ®
                metadata = {
                    "global_step": global_step,
                    "config": config.config_dict,
                    "timestamp": time.time(),
                }
                torch.save(metadata, os.path.join(ckpt_dir, "metadata.pt"))

                print(f"âœ… å·²ä¿å­˜checkpoint: {ckpt_dir}")

            global_step += 1

            if pbar is not None:
                pbar.update(1)
                pbar.set_postfix({
                    "loss": f"{loss.item():.4f}",
                    "lr": f"{optimizer.param_groups[0]['lr']:.2e}",
                })

    # è®­ç»ƒå®Œæˆ
    if pbar is not None:
        pbar.close()

    if is_main and config.wandb_enabled:
        wandb.finish()

    if use_ddp:
        torch.distributed.barrier()
        torch.distributed.destroy_process_group()

    print("ğŸ‰ è½¯ä½“è‡‚Graph VLAè®­ç»ƒå®Œæˆ!")


def main():
    """ä¸»å‡½æ•°"""
    init_logging()

    # è§£æå‘½ä»¤è¡Œå‚æ•° (ç®€åŒ–ç‰ˆ)
    import argparse
    parser = argparse.ArgumentParser(description='è½¯ä½“è‡‚Graph VLAè®­ç»ƒ')
    parser.add_argument('--config', type=str, default=None, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume', action='store_true', help='ä»checkpointæ¢å¤è®­ç»ƒ')
    args = parser.parse_args()

    # åˆ›å»ºé…ç½®
    config = SoftArmTrainConfig(args.config)
    config.resume = args.resume

    # å¼€å§‹è®­ç»ƒ
    train_loop(config)


if __name__ == "__main__":
    main()