#!/usr/bin/env python3
"""
è½¯ä½“è‡‚è®­ç»ƒæµç¨‹æµ‹è¯•è„šæœ¬
åªæµ‹è¯•æ•°æ®æµå’ŒåŸºç¡€ç»„ä»¶ï¼Œä¸éœ€è¦å®Œæ•´OpenPiæ¨¡å‹
ç¬¦åˆLinusåŸåˆ™: æµ‹è¯•æ ¸å¿ƒé€»è¾‘ï¼Œä¸æµ‹è¯•å¤–éƒ¨ä¾èµ–
"""

import os
import sys
import torch
import yaml
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

def test_data_pipeline():
    """æµ‹è¯•æ•°æ®ç®¡é“"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®ç®¡é“...")

    try:
        from data.soft_arm_data_adapter import create_soft_arm_openpi_dataloader

        processed_data_dir = project_root / "data" / "processed"

        if not processed_data_dir.exists():
            print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {processed_data_dir}")
            return False

        # æµ‹è¯•è®­ç»ƒæ•°æ®åŠ è½½å™¨
        train_loader = create_soft_arm_openpi_dataloader(
            str(processed_data_dir),
            split='train',
            batch_size=2
        )

        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        obs_wrapper, actions = next(iter(train_loader))
        obs_dict = obs_wrapper.to_dict()

        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ:")
        print(f"   å›¾åƒå½¢çŠ¶: {obs_dict['image']['camera_0'].shape}")
        print(f"   åŠ¨ä½œå½¢çŠ¶: {actions.shape}")
        print(f"   å›¾æ•°æ®å½¢çŠ¶: {obs_dict['graph_data']['node_features'].shape}")
        print(f"   æŒ‡ä»¤æ•°é‡: {len(obs_dict['instruction'])}")

        return True

    except Exception as e:
        print(f"âŒ æ•°æ®ç®¡é“æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_graph_encoder():
    """æµ‹è¯•å›¾ç¼–ç å™¨"""
    print("\nğŸ§ª æµ‹è¯•å›¾ç¼–ç å™¨...")

    try:
        from models.standalone_graph_encoder import StandaloneGraphEncoder

        encoder = StandaloneGraphEncoder(19, 32)

        # æ¨¡æ‹Ÿå›¾æ•°æ®
        batch_size = 2
        num_nodes = 10
        graph_data = {
            'node_features': torch.randn(batch_size, num_nodes, 19),
            'num_nodes': torch.tensor([6, 8])  # æœ‰æ•ˆèŠ‚ç‚¹æ•°
        }

        with torch.no_grad():
            output = encoder(graph_data)

        print(f"âœ… å›¾ç¼–ç å™¨æµ‹è¯•æˆåŠŸ:")
        print(f"   è¾“å…¥: {graph_data['node_features'].shape}")
        print(f"   è¾“å‡º: {output.shape}")
        print(f"   è¾“å‡ºèŒƒå›´: [{output.min():.3f}, {output.max():.3f}]")

        return True

    except Exception as e:
        print(f"âŒ å›¾ç¼–ç å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_config_loading():
    """æµ‹è¯•é…ç½®åŠ è½½"""
    print("\nğŸ§ª æµ‹è¯•é…ç½®åŠ è½½...")

    try:
        config_path = project_root / "configs" / "debug_config.yaml"

        if not config_path.exists():
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return False

        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)

        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ:")
        print(f"   å®éªŒåç§°: {config['experiment']['name']}")
        print(f"   æ‰¹é‡å¤§å°: {config['data']['batch_size']}")
        print(f"   æœ€å¤§è®­ç»ƒæ­¥æ•°: {config['training']['max_steps']}")
        print(f"   å›¾æ”¯æŒ: {config['model']['graph']['enabled']}")

        return True

    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False

def test_integration():
    """æµ‹è¯•æ•°æ®å’Œæ¨¡å‹é›†æˆ"""
    print("\nğŸ§ª æµ‹è¯•æ•°æ®å’Œæ¨¡å‹é›†æˆ...")

    try:
        from data.soft_arm_data_adapter import create_soft_arm_openpi_dataloader
        from models.standalone_graph_encoder import MockPI0Model

        # åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡æ•°æ®
        processed_data_dir = project_root / "data" / "processed"
        train_loader = create_soft_arm_openpi_dataloader(
            str(processed_data_dir),
            split='train',
            batch_size=1
        )

        obs_wrapper, actions = next(iter(train_loader))
        obs_dict = obs_wrapper.to_dict()

        # æå–å›¾æ•°æ®
        graph_data = obs_dict['graph_data']

        # åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹
        model = MockPI0Model(action_dim=10, action_horizon=16, enable_graph=True)

        # æµ‹è¯•å‰å‘ä¼ æ’­
        with torch.no_grad():
            loss = model(obs_dict, actions, graph_data)

        print(f"âœ… é›†æˆæµ‹è¯•æˆåŠŸ:")
        print(f"   æ•°æ®å½¢çŠ¶æ£€æŸ¥é€šè¿‡:")
        print(f"     å›¾åƒ: {obs_dict['image']['camera_0'].shape}")
        print(f"     åŠ¨ä½œ: {actions.shape}")
        print(f"     å›¾æ•°æ®: {graph_data['node_features'].shape}")
        print(f"   æ¨¡å‹å‰å‘ä¼ æ’­: loss = {loss.item():.4f}")

        return True

    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_device_compatibility():
    """æµ‹è¯•GPUå…¼å®¹æ€§"""
    print("\nğŸ§ª æµ‹è¯•GPUå…¼å®¹æ€§...")

    if not torch.cuda.is_available():
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡GPUæµ‹è¯•")
        return True

    try:
        device = torch.device('cuda:0')

        # æµ‹è¯•æ¨¡æ‹Ÿæ¨¡å‹åœ¨GPUä¸Š
        from models.standalone_graph_encoder import MockPI0Model
        model = MockPI0Model(action_dim=10, action_horizon=16, enable_graph=True).to(device)

        # æ¨¡æ‹ŸGPUæ•°æ®
        observation = {
            'image': {'camera_0': torch.randn(2, 3, 224, 224).to(device)},
            'instruction': ['task 1', 'task 2']
        }
        actions = torch.randn(2, 16, 10).to(device)
        graph_data = {
            'node_features': torch.randn(2, 10, 19).to(device),
            'num_nodes': torch.tensor([6, 8]).to(device)
        }

        with torch.no_grad():
            loss = model(observation, actions, graph_data)

        print(f"âœ… GPUæµ‹è¯•æˆåŠŸ:")
        print(f"   è®¾å¤‡: {device}")
        print(f"   GPUå†…å­˜ä½¿ç”¨: {torch.cuda.memory_allocated()/1e6:.1f}MB")
        print(f"   æŸå¤±å€¼: {loss.item():.4f}")
        print(f"   è¾“å‡ºè®¾å¤‡: {loss.device}")

        return True

    except Exception as e:
        print(f"âŒ GPUæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ è½¯ä½“è‡‚è®­ç»ƒæµç¨‹æµ‹è¯•å¼€å§‹")
    print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")

    # æ£€æŸ¥åŸºç¡€ç¯å¢ƒ
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("é…ç½®åŠ è½½", test_config_loading),
        ("æ•°æ®ç®¡é“", test_data_pipeline),
        ("å›¾ç¼–ç å™¨", test_graph_encoder),
        ("æ•°æ®æ¨¡å‹é›†æˆ", test_integration),
        ("GPUå…¼å®¹æ€§", test_device_compatibility),
    ]

    results = []
    for test_name, test_func in tests:
        print(f"\n{'='*50}")
        print(f"æµ‹è¯•: {test_name}")
        print('='*50)

        success = test_func()
        results.append((test_name, success))

    # æ€»ç»“
    print(f"\n{'='*50}")
    print("ğŸ¯ æµ‹è¯•æ€»ç»“")
    print('='*50)

    passed = sum(1 for _, success in results if success)
    total = len(results)

    for test_name, success in results:
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} {test_name}")

    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! è®­ç»ƒæµç¨‹å‡†å¤‡å°±ç»ª")
        return 0
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é—®é¢˜")
        return 1

if __name__ == "__main__":
    exit(main())