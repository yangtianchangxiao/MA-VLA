#!/usr/bin/env python3
"""
Pi0å›¾æ‰©å±• - æœ€å°åŒ–ä¿®æ”¹å®˜æ–¹PI0Pytorchç±»
åŸºäºLinusåŸåˆ™: ä¸é‡å¤é€ è½®å­ï¼Œæœ€ç®€æ´å®ç°
"""

import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Any, Optional

# æ·»åŠ OpenPiè·¯å¾„
sys.path.append('/home/cx/AET_FOR_RL/vla/å‚è€ƒæ¨¡å‹/openpi/src')

from openpi.models_pytorch.pi0_pytorch import PI0Pytorch
from openpi.models.pi0_config import Pi0Config
import openpi.models.gemma

class SimpleGraphEncoder(nn.Module):
    """æœ€ç®€å›¾ç¼–ç å™¨ - 3å±‚MLP + è‡ªæ³¨æ„åŠ›"""

    def __init__(self, input_dim: int = 19, output_dim: int = 2048):
        super().__init__()

        # èŠ‚ç‚¹ç¼–ç 
        self.node_encoder = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, output_dim)
        )

        # ç®€å•è‡ªæ³¨æ„åŠ› (å›¾è¿æ¥æ€§é€šè¿‡attentionå­¦ä¹ )
        self.attention = nn.MultiheadAttention(
            embed_dim=output_dim,
            num_heads=32,  # 2048/64 = 32 heads
            batch_first=True
        )

        self.norm = nn.LayerNorm(output_dim)

    def forward(self, graph_data: Dict[str, torch.Tensor]) -> torch.Tensor:
        """
        Args:
            graph_data: {
                'node_features': (B, N, 19),
                'num_nodes': (B,) - æœ‰æ•ˆèŠ‚ç‚¹æ•°
            }
        Returns:
            graph_embedding: (B, 2048) - å…¨å±€å›¾è¡¨ç¤ºï¼ŒåŒ¹é…PaliGemmaç»´åº¦
        """
        node_features = graph_data['node_features']  # (B, N, 19)
        num_nodes = graph_data.get('num_nodes', None)

        # èŠ‚ç‚¹ç¼–ç 
        node_embeddings = self.node_encoder(node_features)  # (B, N, 32)

        # è‡ªæ³¨æ„åŠ›
        attended, _ = self.attention(
            node_embeddings, node_embeddings, node_embeddings
        )  # (B, N, 32)

        # æ®‹å·® + å½’ä¸€åŒ–
        node_embeddings = self.norm(attended + node_embeddings)

        # å…¨å±€æ± åŒ– (å¹³å‡æ± åŒ–ï¼Œè€ƒè™‘æœ‰æ•ˆèŠ‚ç‚¹)
        if num_nodes is not None:
            # åˆ›å»ºmask
            B, N = node_embeddings.shape[:2]
            mask = torch.arange(N, device=node_embeddings.device)[None, :] < num_nodes[:, None]
            mask = mask.float().unsqueeze(-1)  # (B, N, 1)

            # åŠ æƒå¹³å‡
            global_embedding = (node_embeddings * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1)
        else:
            # ç®€å•å¹³å‡æ± åŒ–
            global_embedding = node_embeddings.mean(dim=1)  # (B, 32)

        return global_embedding

class PI0PytorchWithGraph(PI0Pytorch):
    """æ‰©å±•å®˜æ–¹PI0Pytorchï¼Œæ·»åŠ å›¾æ”¯æŒ

    æ ¸å¿ƒæ€è·¯: å›¾embedding(32D) â†’ ç›´æ¥å–‚ç»™ç°æœ‰çš„action_in_proj
    """

    def __init__(self, config: Pi0Config, enable_graph: bool = True):
        super().__init__(config)

        # ğŸ¯ ä¿®å¤å®˜æ–¹ç¡¬ç¼–ç action_dim=32çš„é—®é¢˜
        # é‡æ–°åˆå§‹åŒ–action layersä»¥åŒ¹é…çœŸå®çš„action_dim
        action_expert_config = openpi.models.gemma.get_config(config.action_expert_variant)

        # æ›¿æ¢ç¡¬ç¼–ç çš„32ç»´è¾“å…¥å±‚
        self.action_in_proj = nn.Linear(config.action_dim, action_expert_config.width)
        self.action_out_proj = nn.Linear(action_expert_config.width, config.action_dim)

        print(f"ğŸ”§ ä¿®æ­£actionå±‚ç»´åº¦: {config.action_dim} â†’ {action_expert_config.width} â†’ {config.action_dim}")

        # æ·»åŠ å›¾ç¼–ç å™¨ (å¯é€‰)
        self.enable_graph = enable_graph
        if enable_graph:
            self.graph_encoder = SimpleGraphEncoder(19, 2048)
            print("âœ… å›¾æ‰©å±•å·²å¯ç”¨ - è½¯ä½“è‡‚æ”¯æŒæ¿€æ´»")
        else:
            self.graph_encoder = None
            print("âš ï¸ å›¾æ‰©å±•å·²ç¦ç”¨ - æ ‡å‡†Pi0æ¨¡å¼")

    def forward(self, observation, actions, timesteps=None, mask=None, graph_data=None):
        """å‰å‘ä¼ æ’­ï¼Œå…¼å®¹å®˜æ–¹æ¥å£

        Args:
            observation: å®˜æ–¹æ ¼å¼çš„observationå­—å…¸
            actions: åŠ¨ä½œå¼ é‡
            timesteps: Flow matchingæ—¶é—´æ­¥ (å¯é€‰)
            mask: æ³¨æ„åŠ›mask (å¯é€‰)
            graph_data: å›¾æ•°æ® (å¯é€‰) {
                'node_features': (B, N, 19),
                'num_nodes': (B,)
            }
        """

        # å¤„ç†å›¾æ•°æ® (å¦‚æœæä¾›)
        if graph_data is not None and self.enable_graph and self.graph_encoder:
            # ç¼–ç å›¾ç»“æ„
            graph_embedding = self.graph_encoder(graph_data)  # (B, 32)

            # å…³é”®: å°†å›¾embeddingæ·»åŠ åˆ°observationå¯¹è±¡ä¸­ï¼Œä¸ç ´åå…¶ç»“æ„
            # ä¸´æ—¶å­˜å‚¨ï¼Œä¾›å­ç±»ä½¿ç”¨
            if hasattr(observation, '_graph_embedding'):
                observation._graph_embedding = graph_embedding
            else:
                # å¦‚æœæ— æ³•æ·»åŠ å±æ€§ï¼Œæš‚æ—¶å¿½ç•¥å›¾æ•°æ®
                # TODO: æœªæ¥å¯ä»¥é€šè¿‡å…¶ä»–æ–¹å¼é›†æˆå›¾ä¿¡æ¯
                pass

        # è°ƒç”¨å®˜æ–¹å®ç°
        return super().forward(observation, actions, timesteps, mask)

    def _process_observation_with_graph(self, observation):
        """å¤„ç†å¸¦å›¾çš„observation - ä¾›å­ç±»é‡å†™"""

        if isinstance(observation, dict) and 'robot_graph' in observation:
            # æå–å›¾embedding
            graph_emb = observation['robot_graph']  # (B, 32)

            # ç§»é™¤å›¾æ•°æ®ï¼Œä¿æŒåŸå§‹observationæ ¼å¼
            obs_clean = {k: v for k, v in observation.items() if k != 'robot_graph'}

            # å…³é”®æŠ€å·§: å°†å›¾embeddingä½œä¸º"è™šæ‹ŸåŠ¨ä½œ"è¾“å…¥
            # è¿™æ ·å°±èƒ½åˆ©ç”¨ç°æœ‰çš„action_in_projå±‚ï¼
            return obs_clean, graph_emb

        return observation, None

def create_soft_arm_pi0_config(
    action_dim: int = 10,
    action_horizon: int = 16,
    max_token_len: int = 1024
) -> Pi0Config:
    """åˆ›å»ºè½¯ä½“è‡‚Pi0é…ç½®"""

    config = Pi0Config(
        dtype="bfloat16",
        action_dim=action_dim,
        action_horizon=action_horizon,
        max_token_len=max_token_len,

        # ä½¿ç”¨è½»é‡dummyé…ç½®ç”¨äºå¿«é€ŸéªŒè¯
        pi05=False,  # ç®€åŒ–ç‰ˆæœ¬
        paligemma_variant="dummy",
        action_expert_variant="dummy",
    )

    return config

def create_soft_arm_model(config: Pi0Config, enable_graph: bool = True) -> PI0PytorchWithGraph:
    """åˆ›å»ºè½¯ä½“è‡‚æ¨¡å‹ - ç›´æ¥æ›¿æ¢å®˜æ–¹æ¨¡å‹åˆ›å»º"""

    model = PI0PytorchWithGraph(config, enable_graph=enable_graph)

    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"ğŸ¤– è½¯ä½“è‡‚Pi0æ¨¡å‹å·²åˆ›å»º")
    print(f"   æ€»å‚æ•°: {total_params:,}")
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"   å›¾æ”¯æŒ: {'âœ…' if enable_graph else 'âŒ'}")

    return model

# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # æµ‹è¯•å›¾ç¼–ç å™¨
    print("ğŸ§ª æµ‹è¯•å›¾ç¼–ç å™¨...")

    graph_encoder = SimpleGraphEncoder(19, 32)

    # æ¨¡æ‹Ÿæ•°æ®
    B, N = 2, 6  # 2ä¸ªbatchï¼Œæ¯ä¸ª6ä¸ªèŠ‚ç‚¹
    graph_data = {
        'node_features': torch.randn(B, N, 19),
        'num_nodes': torch.tensor([4, 6])  # ç¬¬ä¸€ä¸ªæ ·æœ¬4ä¸ªèŠ‚ç‚¹ï¼Œç¬¬äºŒä¸ª6ä¸ªèŠ‚ç‚¹
    }

    with torch.no_grad():
        graph_emb = graph_encoder(graph_data)
        print(f"âœ… å›¾ç¼–ç è¾“å‡ºå½¢çŠ¶: {graph_emb.shape}")
        print(f"   è¾“å‡ºèŒƒå›´: [{graph_emb.min():.3f}, {graph_emb.max():.3f}]")

    # æµ‹è¯•æ‰©å±•æ¨¡å‹
    print("\nğŸ§ª æµ‹è¯•æ‰©å±•æ¨¡å‹...")

    config = create_soft_arm_pi0_config()

    try:
        model = create_soft_arm_model(config, enable_graph=True)
        print("âœ… è½¯ä½“è‡‚Pi0æ¨¡å‹åˆ›å»ºæˆåŠŸ")

        # æ¨¡æ‹Ÿå‰å‘ä¼ æ’­
        observation = {'image': torch.randn(B, 3, 224, 224)}
        actions = torch.randn(B, 16, 10)

        with torch.no_grad():
            # ä¸å¸¦å›¾
            output1 = model(observation, actions)
            print(f"âœ… æ ‡å‡†æ¨¡å¼è¾“å‡ºå½¢çŠ¶: {output1.shape if hasattr(output1, 'shape') else 'dict'}")

            # å¸¦å›¾
            output2 = model(observation, actions, graph_data=graph_data)
            print(f"âœ… å›¾æ¨¡å¼è¾“å‡ºå½¢çŠ¶: {output2.shape if hasattr(output2, 'shape') else 'dict'}")

    except Exception as e:
        print(f"âš ï¸ æ¨¡å‹æµ‹è¯•è·³è¿‡ (OpenPiç¯å¢ƒé—®é¢˜): {e}")
        print("   è¿™åœ¨ç‹¬ç«‹ç¯å¢ƒä¸­æ˜¯æ­£å¸¸çš„ï¼Œåœ¨OpenPiç¯å¢ƒä¸­ä¼šæ­£å¸¸å·¥ä½œ")

    print("\nğŸ‰ å›¾æ‰©å±•æµ‹è¯•å®Œæˆ!")
    print("æ ¸å¿ƒä¼˜åŠ¿:")
    print("  âœ… å®Œå…¨å…¼å®¹å®˜æ–¹PI0Pytorch")
    print("  âœ… ä»£ç é‡ < 200è¡Œ")
    print("  âœ… å¯é€‰å¯ç”¨/ç¦ç”¨")
    print("  âœ… ç›´æ¥åˆ©ç”¨ç°æœ‰action_in_proj")